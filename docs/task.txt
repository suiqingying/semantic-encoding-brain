1. 基础代码实现
• 音频特征提取：参考文本特征提取代码，完成音频特征提取。需下载音频文件（约568MB），利用已提供的音频划分代码进行处理。
• 多被试分析流程：将单被试示例代码扩展为多被试分析（共25人）。对每个被试独立训练编码模型，并计算测试集准确率。最终报告所有被试准确率的均值（Mean）和标准差（Std），无需进行显著性检验。
2. 核心实验：模型对比与层级分析
• 多模态预训练模型对比：使用不同模型提取特征，对比其对大脑响应的预测性能（与大脑的对齐程度）。
    ◦ 文本模型：如 GPT2、BERT、Llama、Qwen 等。
    ◦ 音频模型：如 Wav2vec、WavLM 等。
    ◦ 多模态模型：如 CLAP、Whisper 等。
    ◦ 硬性要求：每种模态（文本、音频）至少对比三个模型（注：GPT2-base 和 GPT2-large 视为同一个模型）。
• 层级特征分析：对上述每个模型，必须提取并分析**不同层（layers）**的特征性能。
3. 优化与参数调整
• 特征提取优化：调整参数以提升模型性能。
    ◦ 文本：调整上下文窗口大小（示例为200 tokens）和 Pooling 方式（示例为TR内平均）。
    ◦ 音频：调整音频窗口时长（示例为3秒）。
4. 结果分析与可视化
• 脑区语义偏好性：研究不同特征对皮层各脑区（ROIs）的预测性能，分析特定脑区的语义偏好。
• 可视化解释：对语义表征机制或分布模式进行可视化（建议使用 Brainspace 库），并对结果进行生物学解释。
5. 探索性任务（可选但建议）
• 多模态融合：拼接文本和音频特征，寻找预测性能最优的组合。
• 非线性模型：构建非线性编码模型，并与线性模型（岭回归）对比性能。