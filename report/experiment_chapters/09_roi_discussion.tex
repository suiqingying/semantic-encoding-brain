\section{讨论：结果的意义、不足与展望}
本文在统一的编码建模与评估协议下，比较了文本、音频、多模态与特征级融合四类表征对自然故事听觉 fMRI 的可预测性，并以 ROI 统计与皮层脑图给出可视化证据链。讨论部分围绕三个问题展开：第一，这些结果对“语义系统的可预测性与分布式组织”意味着什么；第二，结果中最显著的时间尺度效应应如何理解；第三，在当前实现边界内，哪些不足限制了结论外推，后续应如何扩展以更接近研究动机中提出的问题。

从对齐强弱的全局排序看，音频与多模态模型在 6TR 条件下达到约 0.08--0.09 的均值相关，而文本模型的最佳配置仅约 0.015。这一差异提示，在自然故事听觉范式下，编码模型在当前设置中更容易利用声学与语音相关信息来预测 BOLD 变化，而纯文本语义表征在相同时间对齐方式下贡献较弱。该结论并不与语义地图研究矛盾。Huth 等的语义地图建立在“明确构造的语义特征空间”与“排除或控制声学协变量”的设计之上，并且其特征与任务设置更直接对准语义维度 \cite{Huth2016}；Zhang 等对语义关系的映射同样依赖对语义类别、具体性与关系向量的针对性分析 \cite{Zhang2020}。相比之下，本文的文本特征来自通用预训练语言模型的隐藏状态，其语义信息与句法信息、词形信息及上下文统计规律混合在同一高维空间中，且未在特征层面显式控制声学因素。这意味着“文本模型相关较低”更可能反映在当前对齐与回归设置下，语义信息被多种因素稀释或被声学驱动信号掩盖，而不是意味着语义系统不存在或不可预测。

TR 窗口长度对音频、多模态与融合结果的单调提升，是本文最稳定也最具解释张力的现象。对音频模型而言，窗口从 1TR 增至 6TR 时均值相关从约 0.03 提升到约 0.09，且该趋势在 wav2vec2、WavLM 与 HuBERT 上一致。多模态模型也呈现同样趋势，Whisper-base 从 1TR 的约 0.027 提升到 6TR 的约 0.089，CLAP 也从约 0.023 提升到约 0.079。这说明在自然故事听觉范式下，短窗表征不足以提供对 BOLD 变化稳定可用的线性预测信号，而更长时间范围内的汇聚显著提高了可预测性。自监督语音模型的训练目标本就鼓励模型在更长上下文内整合信息，例如 wav2vec 2.0 的掩码预测需要依赖上下文来恢复被遮蔽片段 \cite{Baevski2020}，而与脑对齐研究指出其层级结构可与皮层语音处理层级对应 \cite{Millet2023}。因此，窗口效应既可能反映模型表征对长程声学统计规律的利用，也可能反映 BOLD 动力学下“可被线性模型捕捉的有效信号”需要更长时间汇聚才能显现。由于本文在 FIR 展开中使用固定窗口与偏移，这两种因素在结果上并未被分离，后续需要更系统地在特征窗口与 FIR 参数上做正交控制，才能区分“输入汇聚”与“动力学建模”各自的贡献。

ROI 统计为“空间偏好”提供了更细粒度的证据。图 \ref{fig:roi_text}、图 \ref{fig:roi_audio}、图 \ref{fig:roi_mm} 分别展示 RoBERTa 文本基线、WavLM 强音频基线与 Whisper-base 强多模态配置的 ROI Top20。尽管本文的 ROI 分区来自固定脑区划分而非体素级地图，但仍可用于观察不同表征在不同功能区域的相对优势。文本基线的 Top ROI 与音频/多模态基线的 Top ROI 之间既有重叠也存在差异，这与语义系统“跨网络分布式组织”的观点一致 \cite{Huth2016,Zhang2020}：同一语义处理过程并不局限在传统语言区，而是涉及默认模式网络、顶叶与颞叶的协同活动。进一步地，Transformer 层级与功能分化分析提示模型内部不同层可能对应不同类型的信息整合，因而其可预测性在不同脑区的分布也可能呈现梯度 \cite{Kumar2024}。本文当前的 ROI 分析只展示了少数代表配置的 Top20 统计，后续可在保持评估协议不变的前提下，对更多层与更多模型绘制 ROI 分布并检验其稳定性，从而把“空间偏好”从单点观察扩展到系统规律。

融合实验提供了一个与多模态模型不同的对照：它不依赖跨模态预训练约束，而是在特征层直接拼接并在联合空间做 PCA。结果显示融合最优配置在 3TR 达到约 0.053，仍显著低于 6TR 条件下的音频与多模态强基线。该现象不应被简化为“文本无用”，因为融合覆盖的时间尺度仅到 3TR，且联合 PCA 可能把文本中较弱但互补的方向压缩掉。更重要的是，融合热图显示层组合存在明显交互而非单调趋势，这与集成建模对“层选择关键性”的强调一致 \cite{Schrimpf2021}，也与 Antonello 与 Huth 提出的“对齐来源可能来自更一般的结构归纳”相呼应 \cite{Antonello2023}：若两种表征空间在某些抽象层级上更匹配，则简单拼接也可能在局部产生收益。要把这一线索推进为更强结论，需要在更长 TR 窗口下补齐融合覆盖，并把融合策略从简单拼接扩展到更明确的跨模态对齐方式，例如在不改变编码模型的前提下对两种特征做对齐子空间学习或分块正则化。

本文也存在明确的不足与边界。其一，本文采用线性岭回归并以单次训练/测试划分在多被试上汇总，避免了交叉验证开销，但也意味着模型选择与不确定性估计较为保守。其二，文本侧上下文窗口固定为 200 token，模型端池化与 TR 内池化的组合在当前结果中并未做系统调参，因而无法回答“更长上下文是否提升语义对齐”这类问题；组合语义研究表明 supra-word 表征依赖精细的控制与比较 \cite{Toneva2022}，而本文目前的文本设置更接近基线而非优化。其三，多模态模型部分虽然包含 Whisper 与 CLAP 的数值结果，但空间可视化与更完整的层级对比仍需补齐；此外，本文未包含连续语义重构那样的解码结果 \cite{Tang2023}，因此讨论严格限定在编码框架内。其四，ROI 级分析虽然提高了稳定性与可解释性，但会平滑掉体素级差异，后续若要更接近语义地图工作中的精细分区，需要在体素级或表面顶点级上复现相同评估逻辑 \cite{Huth2016}。

\InsertFig{roi_roberta_l4.png}{0.86\linewidth}{ROI Top20：RoBERTa-base（win200，layer4）。}{fig:roi_text}
\InsertFig{roi_wavlm6tr_l9.png}{0.86\linewidth}{ROI Top20：WavLM-base-plus（6TR，layer9）。}{fig:roi_audio}
\InsertFig{roi_whisper6tr_l2.png}{0.86\linewidth}{ROI Top20：Whisper-base（6TR，layer2）。}{fig:roi_mm}
