\chapter{预训练模型、层选择策略与特征提取实现}
\subsection{模型集合与本次报告覆盖范围}
本项目将刺激表示划分为三类：文本模型表示、音频模型表示与多模态模型表示。文本模型部分在当前结果中覆盖 \texttt{gpt2}、\texttt{bert-base-uncased} 与 \texttt{roberta-base}；音频模型部分覆盖 \texttt{facebook/wav2vec2-base-960h}、\texttt{microsoft/wavlm-base-plus} 与 \texttt{facebook/hubert-base-ls960}；多模态模型部分覆盖 Whisper（\texttt{openai/whisper-small}、\texttt{openai/whisper-base}）与 CLAP（\texttt{laion/clap-htsat-unfused}）。以上模型的可比较结果体现在 \texttt{results/summary.csv} 中，并且每一条统计记录都可以追溯到对应的 \texttt{results/.../log.txt} 与 \texttt{corr\_layer*.npy} 文件。

在方法论上，本项目遵循“以预训练模型的多层隐藏状态作为可解释特征空间”的通行做法。语言模型方面，ELMo 的深层上下文表示 \cite{Peters2018}、BERT 的双向 Transformer 表示 \cite{Devlin2019} 与 GPT-2 的自回归表示 \cite{Radford2019} 构成了常用对照组，用以区分不同训练目标与不同上下文利用方式对脑预测性能的影响。语音模型方面，自监督框架 wav2vec 2.0 \cite{Baevski2020} 提供了从原始波形到高层语音表征的分层表示，并被用于检验模型对齐是否更接近真实语音加工通路 \cite{Millet2023}。在更宏观的模型比较工作中，大规模集成建模强调“层选择”对脑拟合度的关键作用 \cite{Schrimpf2021,Kumar2024}，同时也提醒我们，模型对齐的来源可能既包含预测目标，也包含更一般的特征发现与迁移能力 \cite{Antonello2023}。

\subsection{层选择：按相对深度等比例取样}
不同预训练模型的层数并不相同，例如多数 base 级 Transformer 编码器为 12 层，而 Whisper-base 的编码器层数更少。如果直接固定使用某些绝对层号（例如一律抽取第 12 层），会导致在浅层模型中越界，或在深层模型中取样过稀，从而让“层对齐差异”混入“层号不匹配”带来的偏差。本项目的层选择采用等比例的相对策略：对每个模型先从配置中读取总层数 $L$，再用等间距取样从 1 到 $L$ 选取若干层，并四舍五入去重得到最终层集合。这一策略的直接结果是：对于 12 层模型，典型层集合为 $\{1,4,6,9,12\}$；对于 6 层模型，则可能得到 $\{1,2,4,5,6\}$。因此，本报告中“layer=k”的含义始终是“该模型结构中的第 $k$ 层”，而不是跨模型共享的绝对语义层级；跨模型比较时，我们把其理解为“从浅到深的相对位置”，并结合每个模型的层数解释其表现。

\subsection{文本特征：上下文窗口与双层池化}
文本特征提取遵循“词级上下文—词级表征—TR 级聚合”的流程。\texttt{src/run\_text\_models.py} 以对齐表为索引，为每个词构造长度为 200 token 的上下文窗口（\texttt{ctx\_words=200}），并将“预分词后的词序列”输入 HuggingFace 模型得到隐藏层输出。代码层面存在两次池化：第一次发生在模型输出端，用于将 token 序列压缩为一个词窗口的向量，支持最后 token 表征或 token 平均；第二次发生在时间对齐阶段，即将同一 TR 内所有词的向量做平均得到 TR 级表示。当前结果文件对应的实现采用“模型端取 last token 表征，TR 内对词向量做平均”的组合，这与自然语言理解中“当前词由其左侧上下文决定”的建模假设一致，并且可以将变长词序列稳定映射到定长向量。

\subsection{音频特征：TR 窗口切分与帧级池化}
音频特征提取遵循“波形分片—模型表征—窗口池化”的流程。整段音频以 16kHz 采样率读取后，按 TR 窗口切分为若干 chunk；每个 chunk 输入音频模型得到时间序列隐藏状态，再用 attention mask 对有效帧做平均池化得到单个向量。当前结果系统比较了 1TR、2TR、3TR、6TR 等多种窗口长度，目的在于检验更长的声学上下文是否有助于在 BOLD 延迟下提高可预测性。

\subsection{多模态特征：模型内部融合与 TR 对齐}
多模态模型的关键区别在于其输出不是“纯音频编码器的表示”，而是模型结构中显式对齐或融合了文本与音频信息后的表示。Whisper 属于编码器—解码器结构，本项目使用其编码器侧的表示作为与输入语音相关的表征来源，并对不同层进行比较；CLAP 同时包含音频与文本编码器，输出位于共享嵌入空间的音频表示，本项目将其视为多模态对齐框架下的表示来源，并在同样的 TR 窗口切分策略下进行评估。由于不同多模态模型对输入形式与采样率存在约束，当前报告仅讨论在 \texttt{results/} 中已经成功产出 corr map 的配置。
