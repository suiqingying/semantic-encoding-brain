\section{数据、对齐表与 TR 级刺激构建}
本项目使用的原始文件位于 \texttt{data/raw/}。fMRI 数据以 ROI 形式预先整理为 \texttt{21styear\_all\_subs\_rois.npy}，对齐表位于 \texttt{21styear\_align.csv}，音频刺激位于 \texttt{21styear\_audio.wav}。\texttt{src/data.py} 将这些文件加载为可被特征抽取与编码建模直接使用的结构：\texttt{load\_fmri()} 返回一个以被试编号为键的字典，每个条目是形状为 $(T,360)$ 的矩阵，表示 $T$ 个 TR 上 360 个 ROI 的 fMRI 信号；\texttt{load\_audio()} 以固定采样率读取整段音频；\texttt{load\_align\_df()} 读取对齐表并为每个词构造 TR 编号。

对齐表 \texttt{21styear\_align.csv} 每行包含四列：保留大小写的词、全部小写的词、词开始时间戳（秒）与词结束时间戳（秒）。对齐表中存在缺失项，代码对时间戳进行向后填充，并将缺失词以 \texttt{none} 作为占位。随后根据 TR 时长将词级时间戳映射到离散 TR 索引。项目设置 TR 为 1.5 秒，因此对于词开始时间 $t$（单位秒），对应 TR 索引为 $\lceil t/\mathrm{TR}\rceil$。这一步的输出是一个包含 \texttt{tr} 列的数据框，它把每个词归入某一个 TR，从而为后续“把词级特征聚合为 TR 级特征”提供了确定的分组键。

TR 级刺激构建需要同时处理三条时间轴：词级时间轴（用于文本与文本端对齐）、连续波形时间轴（用于音频分片）、TR 采样时间轴（用于与 fMRI 对齐），以及 BOLD 延迟轴（用于 FIR 延迟展开）。本项目对文本与音频采取统一的策略：先在原始粒度上抽取预训练模型特征，再将特征聚合到 TR。对于文本而言，\texttt{src/text\_pipeline.py} 先为每个词构造上下文窗口（默认 200 token），输入语言模型得到词级或 token 级表征，随后按 \texttt{tr} 分组，对同一 TR 中所有词的表征求均值得到 TR 级文本特征。运行时可能出现 pandas 的 FutureWarning，这属于 API 行为变更提示，不影响当前版本下的数值计算与输出文件。

对于音频而言，连续波形根据 TR 窗口切分为一系列 chunk。配置 \texttt{src/config.py} 中的 \texttt{AUDIO\_SR=16000} 表示采样率为 16kHz；当窗口设置为 1TR、2TR、3TR、6TR 时，分别对应 1.5s、3.0s、4.5s、9.0s 的音频片段。每个片段作为一个输入样本送入音频模型得到表示，形成与 TR 一一对应的序列。窗口长度不仅决定了音频表征是否覆盖跨 TR 的韵律与语音单位结构，也会与 FIR 延迟展开共同决定“刺激历史覆盖范围”，因此音频模型部分会系统比较不同 TR 窗口的效果。

为了使后续编码模型稳定训练，特征在进入回归之前会进行降维。当前实现默认使用 PCA 将 TR 级特征降到 250 维（\texttt{DEFAULT\_PCA\_DIM=250}），其目的在于减轻高维特征与有限样本量组合导致的病态问题，并降低回归求解成本。所有预处理都在特征与脑信号完成 TR 级对齐之后进行，从而保证特征矩阵与 fMRI 的时间轴严格一致。
