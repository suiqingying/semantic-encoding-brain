\section{实验材料、对齐表与 TR 级刺激构建}
本项目的数据由三部分组成：被试在听自然故事时的全脑 fMRI 信号、对应的音频刺激以及文本转写与时间对齐信息。fMRI 的采样以 TR 为单位，项目配置中 TR 时长为 1.5 秒。为了让编码模型的输入与输出处在同一时间轴上，刺激特征必须被构造为长度等于 TR 序列的时间序列，并且每个时间点的特征仅由其对应时间范围内的刺激确定。自然故事范式之所以对对齐提出更高要求，是因为词与声学帧在连续时间中密集出现，且叙事结构会跨越多个 TR 累积；若对齐偏差达到 TR 量级，编码性能会被系统性压低，从而无法解释模型与脑之间的真实差异 \cite{Huth2016}。

文本侧对齐采用“词级时间戳 → TR 索引”的映射。对齐表记录每个词在音频中的出现顺序以及其对应 TR 编号，并提供规范化后的词形字段用于构造上下文窗口。本文在特征提取阶段先为每个词构造一个上下文序列，再从预训练语言模型提取词级表示；随后在 TR 对齐阶段，把属于同一 TR 的词向量做平均得到 TR 级文本特征。由于自然故事中不同 TR 的词数并不均匀，某些 TR 可能只有少量词甚至缺失词条，代码实现使用前向填充将缺失 TR 的特征延续为最近的已观测特征，从而得到与 fMRI 序列严格等长的输入矩阵。该处理并不引入新的语义信息，而是把“当前语境”视为在短时间内保持不变的近似，这一近似也与 BOLD 的时间平滑性质一致。

音频侧对齐采用“TR 窗口切分”。首先将整段音频以 16 kHz 采样率读入，随后按 TR 秒数计算每个 TR 对应的采样点数，并以步长为 1 个 TR 的滑动方式切分为长度为 $w$ 个 TR 的音频片段，其中 $w$ 为 TR 窗口长度（例如 1TR、2TR、3TR、6TR）。每个音频片段输入预训练音频模型后得到帧级隐藏状态，再在时间维上做池化得到片段级向量；由于切分步长等于 1TR，片段序列天然与 TR 序列对齐，得到长度为 TR 数的音频特征矩阵。通过改变窗口长度 $w$，我们可以直接检验“更长的声学上下文”是否在当前编码框架下提高可预测性，从而把时间尺度作为与层级结构并列的可比较维度。

多模态模型在本项目中以“对齐到 TR 的可用输出”为基本原则：对于 Whisper 类编码器—解码器模型，我们以音频窗口与 TR 对齐的方式得到输入片段，并从模型内部可获得的隐藏状态构造片段级表征；对于 CLAP 类双编码器模型，我们以相同的音频片段作为输入，并结合对齐表构造同一窗口内的文本字符串，从而在共享嵌入空间中得到可回归的 TR 级多模态表征。无论哪一种模型，最终进入编码模型的输入都被表示为形状为 $(T, D)$ 的矩阵，其中 $T$ 为 TR 数，$D$ 为经池化与降维后的特征维度。
