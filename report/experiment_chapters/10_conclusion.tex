\section{结论}
本文以自然故事听觉范式下的多被试 fMRI 数据为对象，在统一的对齐、降维与时延展开流程下构建线性编码模型，系统比较了文本模型、音频模型、多模态模型及文本--音频特征拼接融合对脑信号的可预测性。结果在当前已生成文件范围内呈现出清晰的经验结构：文本模型在固定 200 token 上下文窗口与 TR 内平均聚合的设置下提供了较弱但可追溯的语义基线；音频模型与多模态模型在更长 TR 窗口下显著提高可预测性，并在 6TR 条件下达到约 0.08--0.09 的均值相关；融合在覆盖到 3TR 的范围内呈现稳定的窗口提升与层级交互结构，但其最优均值仍低于强音频/多模态基线。ROI 统计与皮层脑图可视化进一步表明，不同表征在空间分布上既有共性也存在差异，为后续围绕语义系统分布式组织与模型层级功能分化的分析提供了可视化基础 \cite{Huth2016,Zhang2020,Kumar2024}。

在方法层面，本文的贡献在于给出一条可复现的证据链：每个配置的数值统计、corr map 与图像输出都可以在仓库中逐项对应并核验，从而使跨模型比较建立在统一评估协议之上。与此同时，本文也明确了当前边界：线性编码与单次训练/测试划分限制了对不确定性的估计；文本侧上下文窗口与池化策略尚未系统调参；融合覆盖的时间尺度与层覆盖仍有限；多模态模型的空间分析仍需在绘图输出更完整后补齐。

在后续工作中，最直接的扩展路径是围绕“时间尺度”与“层级位置”做更充分的正交比较，并在不改变数据与总体评估逻辑的前提下提升文本与融合基线的强度。结合相关工作中的语义地图、组合语义与自监督语音层级对齐研究，这些扩展有望把本文当前的系统比较推进到对“哪些信息类型在何种时间尺度与层级位置上更接近可测脑信号”更有约束力的结论 \cite{Schrimpf2021,Antonello2023,Millet2023,Toneva2022}。
