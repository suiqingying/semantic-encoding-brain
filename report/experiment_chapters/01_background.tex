\section{背景与研究问题}
\begin{tcolorbox}[
  enhanced,
  breakable,
  colback=Nord6,
  colframe=Nord8,
  frame hidden,
  leftrule=4pt,
  arc=2mm,
  left=12pt,right=10pt,top=10pt,bottom=10pt
]
{\TitleCJK\bfseries\Large\color{Nord10}小组成员与分工}\par
\vspace{0.6em}
{\renewcommand{\arraystretch}{1.25}%
\begin{tabularx}{\linewidth}{@{}p{0.34\linewidth}X@{}}
\MemberInfo{\StudentName}{\StudentID}{panyuxuan231@mails.ucas.ac.cn} & \vspace{0pt}负责整体方案设计与实现；完成文本/音频/多模态与融合特征提取、线性编码模型与评估、ROI 分析与可视化；整理结果并撰写报告。\\[0.6em]
\MemberInfo{林俊杰}{N/A}{N/A} & \vspace{0pt}未参与本次实验执行与代码实现。\\[0.6em]
\MemberInfo{王煜}{N/A}{N/A} & \vspace{0pt}未参与本次实验执行与代码实现。\\[0.6em]
\MemberInfo{李向阳}{N/A}{N/A} & \vspace{0pt}未参与本次实验执行与代码实现。\\[0.6em]
\MemberInfo{朱奕}{N/A}{N/A} & \vspace{0pt}未参与本次实验执行与代码实现。\\[0.6em]
\end{tabularx}}
\end{tcolorbox}

本项目研究的问题是：在自然故事听觉范式下，预训练模型得到的刺激表征在多大程度上能够预测全脑 fMRI 响应，并且这种“对齐程度”在不同模态（文本、音频、多模态）与不同模型层级之间如何变化。该问题的出发点来自两条相互推进的研究线索。第一条线索是自然语音刺激下的语义系统映射。Huth 等使用长时自然故事并构建体素级编码模型，证明在严格的未见故事评估下，线性回归可以得到稳定可复现的语义地图，从而将“可预测性”作为语义表征的可测证据 \cite{Huth2016}。Zhang 等进一步把分析单位从语义类别扩展到语义关系，指出概念与关系并非由解剖上隔离的模块分别承载，而是通过跨网络的重叠模式编码并支持语义推理 \cite{Zhang2020}。第二条线索来自预训练模型与大脑对齐的集成建模。Schrimpf 等在统一评估协议下系统比较不同架构与不同层，发现 Transformer 模型通常更能解释语言相关脑区的活动，并强调跨模型的可比性与评估一致性 \cite{Schrimpf2021}。然而，“语言模型拟合脑数据”并不自动推出“大脑在执行下一词预测”。Antonello 与 Huth 通过多项分析指出，模型对齐可以由更一般的特征发现与语言结构归纳解释，且模型内部最擅长预测未来词的层并不必然是最佳脑编码层 \cite{Antonello2023}。因此，本项目把“多模型、多层”作为基本比较单位，以避免仅凭单一指标外推机制结论。

自然故事听觉范式的另一个关键维度是时间尺度。BOLD 信号相对刺激存在血氧动力学延迟与时间平滑，因此对齐必须同时解决“刺激与 TR 的时间对应”和“刺激对 BOLD 的时延影响”。语义地图研究通常通过把词级语义特征聚合到 TR，并在回归输入端引入时延展开来吸收动力学差异 \cite{Huth2016}。在本项目中，我们把这一逻辑推广到预训练模型特征：文本侧以 token 上下文窗口构造词级表示，再聚合到 TR；音频侧以 TR 窗口切分语音波形，把短时帧级隐藏状态池化为每个 TR 的表征，再进入同一回归框架。由于时间尺度会影响模型能否捕获长程语境，本项目还系统比较不同 TR 窗口长度对音频与多模态表征的影响，并在融合实验中检验跨模态信息是否互补。

在模型选择上，本项目覆盖三类表征。文本模型选用 GPT-2、BERT 与 RoBERTa，分别代表自回归 Transformer、双向 Transformer 与改进的掩码建模框架；这些模型作为上下文表征的代表，在以往语言脑对齐研究中常被用于区分不同预训练目标对表征结构的影响 \cite{Peters2018,Devlin2019,Radford2019}。音频模型选用 wav2vec2、WavLM 与 HuBERT，它们属于以波形为输入的自监督/弱监督语音表征家族，其中 wav2vec 2.0 的掩码预测目标为“从上下文恢复被遮蔽的离散语音单元”提供了具体实现 \cite{Baevski2020}；相关研究表明这类模型在层级上呈现从声学到更抽象结构的渐变，并能在一定程度上对齐皮层的语音处理层级 \cite{Millet2023}。多模态模型部分覆盖 Whisper 与 CLAP 等模型的可用输出，用于检验“多模态训练或共享嵌入空间”是否能带来超越强音频基线的可预测性，并观察其空间分布是否更接近语义系统。

在研究问题的表述上，本文不把对齐结果直接解释为某一种认知机制的证据，而是以可复现的证据链回答三个可检验的问题。第一，在统一的编码评估框架下，不同模态与不同模型的对齐强弱排序如何，哪些配置构成强基线。第二，在模型内部的层级结构上，最佳层是否稳定出现在中间层或深层，以及这种层级位置是否与时间窗口长度共同作用。第三，当文本与音频特征进行简单拼接融合时，性能是否出现稳定提升，并且最佳文本层与最佳音频层是否呈现非单调交互。讨论部分将在这些结果约束下结合组合语义与 supra-word 表征观点 \cite{Toneva2022}、Transformer 功能分化分析 \cite{Kumar2024}、以及语义重构方向的互补视角 \cite{Tang2023}，对结果的意义、不足与后续扩展方向作出解释。
