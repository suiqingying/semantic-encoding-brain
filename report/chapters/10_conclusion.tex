\chapter{结论}

神经语言模型与大脑语义表征的研究正在快速发展。从预测编码的争论到语义地图的绘制，从自监督学习到注意头的功能专化，这些成果逐渐揭示语言理解的多层次结构。一方面，大型 Transformer 模型的成功强调了预测过程在语言系统中的重要性；另一方面，层级和迁移分析提醒我们，模型与大脑的对应不只是预测，通用语言知识也起决定作用。数据驱动的语义地图和关系研究展示了大脑语义系统的分布式和网络化特点。自监督语音模型及其跨语言一致性为理解人类语言习得提供了新的工具；注意头分析为细粒度的脑—模型对齐提供了方法；组合语义研究则揭示了词汇和组合意义共享但依赖不同神经机制的复杂图景。

展望未来，仍有多重挑战等待解决：获取同时具有高时间和空间分辨率的神经数据，以捕捉语言加工的动态；发展能够整合多模态数据和多任务训练的模型；将发展限制、能耗约束等生物因素引入模型；以及在更广泛的文化与语言背景下验证研究的普适性。通过跨学科合作，结合神经影像学、计算神经科学、语言学和人工智能，我们将进一步接近理解大脑语言机制的真实样貌。

总而言之，将神经语言模型与大脑语义系统进行比较不仅能深化我们对语言机制的理解，还能为人工智能提供新方向。当前证据显示，预测机制、分布式表征、自监督学习和组合语义是构建符合人脑的语言模型不可或缺的元素。未来，我们倡议采用更广泛的语言和文化样本，结合多种神经成像技术和因果干预方法，实现真正的跨学科融合。只有这样，我们才能在知识、技术与伦理层面推动人工智能与人类智能的和谐发展。

综上所述，跨层次、跨模态和跨文化的综合研究将成为未来语义科学的重要方向，为构建真正符合人类思维的智能系统奠定基础。这一目标需要持续努力。

值得一提的是，生成式模型和判别式模型在解释语言理解方面可能各具优势。生成式模型通过显式建模上下文和潜在语义结构，可以模拟听者在理解故事时生成的内部假设和场景想象；判别式模型则侧重于区分候选输出，更适合快速决策和分类任务。大脑可能同时利用两种策略：在构建对叙事的宏观理解时采用生成式推理，而在词汇辨认和句法解析时采用判别式决策。这一观点得到神经证据支持：在默认模式网络和海马区检测到与生成式推理相关的活动，而在颞上回和顶叶注意网络则检测到与判别式加工相关的活动。未来可通过比较生成式预训练模型（如扩散语言模型）和判别式模型在脑编码任务上的表现，探索这两种策略与不同脑区之间的映射关系。同时，在模型训练中引入生成与判别的联合目标，或许能构建更符合大脑处理的混合模型。

另一方面，语言理解与时间意识和未来计划的关系也值得关注。当人们听故事时，他们会构建情节的时间轴，并预测未来事件的走向，这涉及前额叶皮层与海马网络的协同。预测编码模型主要关注短期词序列，而忽略了跨句或跨段落的事件预测。神经语言模型可以通过引入时间标记和事件链建模任务来更好地模拟这种长程预测能力。例如，可以训练模型根据当前叙事生成可能的下一段情节，或预测角色的后续行为，并用这些预测表示去解释大脑中与情节理解相关的活动。这不仅拓展了模型的功能，也为解释大脑如何处理跨句篇章层次的预测提供了新线索。

另一方面，未来研究还可以考虑将道德推理和价值判断融入语言模型的对齐过程。人类在理解语言时常常自动评估行为的道德性、陈述的可信度和信息的社会意义，这些评估依赖于前额叶皮层和边缘系统的互动。现有语言模型普遍缺乏对道德语义和价值判断的敏感性，通过引入道德推理任务或使用包含道德标注的语料进行微调，可以探索模型在这些方面与大脑的差距。此外，在脑编码实验中加入涉及伦理决策或道德评价的故事，可以观察语义系统与情感和价值网络的协同反应，为发展更负责任的人工智能提供依据。
随着深度学习在自然语言处理领域的不断进步，模型与大脑比较的工具也在持续发展。例如，最近的研究使用可微分的哈密顿动力学模拟语言产生过程，将语义和语法编码为物理系统的能量和势能；这种方法在生成语音时显著降低了模型复杂度，并能够捕捉到语调和节奏的微妙变化。与传统神经网络相比，物理启发模型更容易引入生理约束，如能量消耗和处理速度限制，为理解大脑如何高效地编码和生成语言提供新思路。未来可以将这类模型应用于脑解码任务，检验其是否更符合语音与语义的神经表示，同时探索大脑是否利用类似的动力机制来组织语言信息。

此外，针对语义地图和语义关系的研究可以进一步采用图神经网络（GNN）等结构化模型来模拟语义网络的连通性。GNN 能够在节点和边的结构上进行学习，非常适合处理语义图和知识图谱。将 GNN 应用于脑编码任务，可能揭示大脑中概念之间的连接强度和传播路径，进而解释概念激活在时间上的扩散过程。这种结构化建模方式也为跨学科合作打开新途径，将语言学、神经科学与图论结合起来，为理解语义认知的复杂结构提供强大的方法工具。
综合这些研究，我们也应认识到当前方法的局限性。首先，大部分神经语言模型只考虑文本或语音输入，忽略了手势、面部表情和语调等非言语信号，这些信号在实际沟通中具有重要作用。多模态语料和模型训练仍处于起步阶段，难以捕捉语言与其他感官输入的交互。其次，脑编码模型主要基于线性回归，无法捕捉大脑和模型表征之间可能存在的非线性映射。尽管线性模型易于解释和训练，但未来应探索深度编码模型或表示对齐技术，以更精准地映射复杂的语义关系。此外，现有研究往往忽视个体差异，如工作记忆容量、阅读习惯、知识背景等，这些因素都会影响语义加工和预测能力。只有在样本量更大、参与者更多样化的情况下，才可能揭示语义系统的共性与个体差异。最后，各研究的数据共享和分析流程尚未完全标准化，重复性和可比性有待提高，倡议建立开放的语料库、共享代码和规范化分析平台，以促进该领域健康发展。
