\section{预测编码理论及其争议}

\subsection{预测编码的基本思想}
预测编码（predictive coding）是一种流行的认知理论，它认为大脑通过不断生成对未来输入的预测来高效加工感知信息。大脑产生内部模型预测即将到来的刺激，并通过比较预测与实际输入的偏差（预测误差）更新内部模型，从而在多层次上实现感知和理解。这一框架最早在视觉系统提出，随后扩展到听觉和语言领域。语言过程中，大脑可能利用上下文信息预测接下来要出现的词语、语法结构或语义内容，减少加工负担。行为实验和脑电研究（如 N400、P600）提供了一些间接证据，表明当语句违背语法或语义预期时会出现特异的神经反应。

人工神经网络语言模型（NNLM）因其训练目标与预测未来词语相关，被视为测试预测编码假说的理想工具。语言模型通常通过最大化下一个词的概率来进行自监督学习，这使模型的隐藏表示内化了大量语法、语义和篇章结构信息。如果人脑确实在理解语言时进行类似预测，那么这些模型的表现应与人脑活动高度一致。一些早期研究发现，基于 RNN 或 Transformer 的语言模型可以解释大量语言相关脑区的活动，且模型的预测准确率与脑解码性能呈正相关。这些结果被视为支持大脑预测编码的证据。

需要强调的是，语言中的预测可能涉及不同层次：在语音层面，人类利用共现概率预测下一个音素或重音；在词法层面，预测词的词形和词性；在句法层面，预测短语结构和句法角色；在语篇层面，预测话题发展或叙事结构。人脑可能在这些层次上并行生成预测，而当前神经语言模型主要专注于词序列层面的预测，忽视了语音和句法层面的单独预测。此外，语言模型中的误差信号仅用于训练过程，推理时不会在层间反馈，而预测编码理论强调误差信号自下而上传递、更新内部模型。早期 ERP 指标如 N400 与 P600 虽常被解释为语义或句法预测误差，但也有研究认为它们反映语义整合困难、冲突监控或重新分析等多种认知过程。因此，尽管神经语言模型的成功为预测编码提供了重要线索，我们仍需谨慎区分模型的预测目标与大脑真实的预测机制。

预测编码理论起源于贝叶斯大脑假说，将大脑视为一个生成模型，在每个时间步预测感官输入的概率分布，并通过最小化预测误差维持内外信息的一致性。在语言领域，这意味着不仅要预测即将出现的词，还要预测其词法形态、语法角色以及在语篇中的功能。例如，英语的限定词后可能接名词，而日语中的助词指示了不同的语法关系，大脑需要根据语言的语法规则调整其预测。不同语言之间的词序和结构差异也挑战了简单的线性预测框架，提示预测可能是多层次、动态调整的过程。

另一个相关的理论是生成式模型，它认为大脑在理解语言时会构建一个潜在的生成过程，形成关于事件、场景或对话的内在模型。这种生成式推理不仅包含预测，还涉及假设检验和信念更新。例如，在叙事理解中，听者会建立角色间的因果关系和动机结构，对即将发生的情节做出推断。当新信息与内在模型不符时，大脑将产生突出的预测误差信号，从而驱动理解的修正。神经语言模型多采用自回归训练，但真实生成过程可能依赖递归和层次化的预测，这也是模型尚未完全捕捉到的。

预测编码的思想早在上世纪九十年代在视觉系统提出，Rao 和 Ballard 提出了一个分层模型，上层神经元产生低层输入的预测，下层神经元反馈误差信号驱动上层更新。在听觉和语言研究中，类似的框架用于解释为什么语境越丰富，大脑的听觉皮层响应越弱：这种现象被解释为预测误差减少。该理论强调自上而下连接的作用，认为皮层层次之间通过反馈信号调节编码。但大脑皮层的解剖显示出复杂的双向连接，预测编码模型如何映射到这些解剖结构仍具争议。例如，颞上沟的层间连接既有前馈也有反馈，高层视皮层与耳蜗的反馈回路则难以用简单的预测误差解释。此外，语言中的冗余和多义性使得预测必须结合词义和语境，不同语言的后缀、语序自由度也影响预测策略。为了准确评估预测编码理论，研究需要在不同语言和任务上系统测量预测误差信号，并区分语法预测、语义预测和语用推理。

在预测编码的讨论中，还需区分不同层次的预测目标。生成式贝叶斯模型强调，大脑不仅预测即将到来的感官输入，还预测输入的原因。例如，听到特定音节后，大脑可能预测未来出现的语义类别或句法角色，而不仅是具体词形。语言理解涉及对外界事件和他人意图的建模，这种隐式推理远超下一词预测。研究发现，当叙事违反人物动机或事件因果时，大脑的默认模式网络产生强烈反应，但这与词层面的 surprisal 无关。另一方面，预测并非总有利于理解；在幽默或修辞反转中，出乎意料的表达反而提高了记忆和理解。神经语言模型通常通过最大化下一个词的概率学习，但大脑在面对新颖和意料外的句子时可能主动抑制预测，以保持开放性。因此，未来实验应将预测难度、句式复杂度和语用意图作为独立维度操控，通过组合这些因素进一步测试预测编码假说的边界。此外，生成式模型与分布式语义模型并非对立，可通过变分自编码器等框架联合实现预测与解释；这些模型能同时学习生成过程和意义结构，为理解大脑如何整合预测与概念知识提供新的工具。

\subsection{对预测编码证据的质疑}
尽管语言模型在脑编码任务上的成功常被用作预测编码的证据，但这一推论遭到质疑。Antonello 与 Huth（2023）\cite{Antonello2023}对神经语言模型与大脑匹配的机制进行了细致分析。他们发现，同一模型的不同层在解释大脑活动时表现迥异：用于词预测任务的高层隐藏状态并非最佳的神经预测器，相反，中间层的表示更能解释大脑数据。此外，他们提出了一个衡量模型在多种下游任务上迁移能力的“通用迁移性能”指标。研究发现，该指标与模型的脑编码性能同样相关，而与下一词预测性能的关系并不更强。因此，模型在大脑编码任务中的成功可能源自其学习到的丰富语言结构，而不仅仅是预测任务本身。

另一个支持这一观点的证据来自层级分析。对比模型不同层的表示，研究者发现中层能够捕获局部依存和语义结构，而高层则更专注于全局预测。在大脑编码任务中，中层表示的解释方差显著高于高层表示。如果预测编码是唯一关键因素，理论上最擅长预测任务的高层应该最能解释大脑活动，但事实恰恰相反。该研究因此提醒，不能简单把模型的预测目标与大脑的认知目标等同，也不能基于模型的预测准确率直接推出大脑采用预测机制。

在质疑预测编码假说的工作中，Antonello 与 Huth 对神经模型与大脑匹配度展开系统性检验。其数据集由五名健康成人组成，每名受试者在多次扫描中聆听约五小时的英语播客故事。研究者构建了 97 个特征空间，包括词向量、模型不同层的隐藏状态以及手工设计的语言学特征，并通过 Lanczos 插值将这些特征时间序列与 fMRI 采样率对齐。在回归模型中，他们分别比较不同特征对体素级响应的解释能力，结果显示，Transformer 模型的中层表示在预测脑活动时普遍优于后层和早层，且这种优势在不同被试和不同脑区中一致。

除了层级分析，研究者还引入通用迁移性能指标，用以衡量模型在情感分析、命名实体识别、翻译等多任务上的表现。令人惊讶的是，该指标与脑编码性能的相关性与下一词预测相当，甚至在某些情况下更强，这表明模型的迁移能力可能比其预测能力更能反映大脑语言处理的本质。这一发现促使我们重新思考预测编码假说的适用范围：语言理解可能依赖多种学习机制，如统计学习、结构学习和语义推理，而不仅是简单的下一词预测。此外，作者强调，未来研究应通过实验操控模型的训练任务，如比较纯预测任务与多任务学习模型在脑编码中的差异，从而更严格地检验预测编码的贡献。

Antonello 与 Huth 的质疑工作不仅比较了模型层级的性能，还分析了由语言学家手工标注的特征，如词性、句法依存树、形态标签等。他们发现，这些传统特征单独时预测脑活动的能力远低于神经模型表示，但将其与模型嵌入组合可以略微提升性能，表明模型捕获的高级特征包含这些语言学信息。值得注意的是，他们使用约 5 小时的自然播客故事，总共约 45000 个单词，几乎涵盖多种主题和叙事风格。研究者利用卷积插值将单词特征对齐到 fMRI 时间点，并采用嵌套交叉验证确保统计可靠性。这样的严谨设计减少了过拟合风险，也为其他研究提供了基准。作者还指出，模型在任务外迁移性能上的表现和语法性判断、语义相似度等任务的相关性不高，这表明各任务衡量的语言能力不同，未来应构建多维评估指标综合评估模型与大脑的对应。

\subsection{集成建模对预测性的支持}
与上述质疑相对，另一系列研究采用大规模集成建模方法，通过比较不同模型、不同任务和不同数据集，系统检验模型性能与大脑匹配度之间的关系。Schrimpf 等（2021）\cite{Schrimpf2021}汇集了 43 种语言模型，包括不同深度的 Transformer、循环神经网络（RNN）和静态词向量，并对比它们在多个神经和行为数据集上的表现。数据集包括人们阅读或听句子时的 fMRI 和 ECoG 信号以及反应时间等行为指标。结果表明，Transformer 模型显著优于 RNN 或静态嵌入，容量越大性能越好。更重要的是，模型的脑拟合度、行为拟合度与其下一词预测准确率之间存在显著正相关，而与其他语言任务（如句法分析、文本分类）无关。此外，未训练的 Transformer 也能解释部分大脑数据，表明模型架构对匹配度有基础性贡献。

综上，集成建模似乎支持预测编码：能够更好预测下一词的模型往往更能解释大脑数据。然而，这种关联并不能排除其他解释。例如，大型模型在训练过程中捕获了更丰富的语言统计规律，其表现优异可能来自于表示的复杂性而非预测任务本身。因此，预测与特征学习之间的贡献仍需通过控制实验加以区分。

集成建模工作汇聚了多个数据集，旨在探索模型性能与脑匹配度之间的普遍规律。Pereira2018 数据集包括 78 名参与者在阅读约 400 个句子时的 fMRI 信号，每个句子呈现多次以提高信噪比。Fedorenko2016 数据集采用 ECoG，记录 12 名癫痫患者在阅读单词或短语时的皮层电活动，具有高时间分辨率，适合分析迅速的语音和语义过程。Blank2014 数据集让参与者聆听约五分钟的自然故事，捕捉更生态的语篇处理。通过在这些数据集上对 43 个模型的各层表示进行线性回归，研究者发现模型的脑拟合度与下一词预测准确率之间呈现强相关，且 Transformer 模型几乎达到了噪声上限。

深入分析表明，模型架构对大脑匹配度的贡献不可忽视。即便未经训练，Transformer 架构也能在一定程度上预测脑活动，这表明多层自注意结构本身具有与语言网络相似的组织方式。此外，模型的容量越大，匹配度越高，提示大脑语言系统可能利用高维表征整合丰富的语境信息。集成建模还强调，模型在其他语言任务（如问答、句法分析）上的性能与脑拟合度几乎不相关，说明预测任务在当前模型框架中仍然是最能反映大脑语言处理的代理任务。然而，这并不意味着大脑只做预测，而可能是目前的预测任务同时涵盖了语义、语法等多维信息，所以表现出较强的相关性。

Schrimpf 等人的集成建模研究除了下一词预测任务，还评估了模型在机器翻译、问答、句法分析等任务上的性能。他们发现这些任务的准确率与脑拟合度之间相关性较低，这意味着大脑理解语言可能不依赖模型在某些人工任务上的表现。研究还发现，不同受试者、不同刺激材料和不同脑区之间的匹配度差异较小，说明某些规律具有普遍性。他们还使用双任务对比，比较随机初始化模型、预训练模型和经过微调的模型，结果显示预训练是获得高脑拟合度的关键，而微调对特定任务并不能显著提升脑对齐。这一观察支持了模型通过大规模无监督学习捕获人类语言统计结构的重要性，同时也提示未来模型设计应优先考虑预训练阶段的任务和数据多样性。

集成建模之所以能够揭示模型性能与脑拟合度的关系，得益于对多样数据集和多重评测指标的系统整合。Schrimpf 等人在比较 43 个语言模型时，不仅考虑模型的下一词预测准确率，还综合了模型规模、层数、训练语料大小以及是否使用双向或自回归架构。他们发现模型容量与脑拟合度呈非线性关系，层数增加初期可显著提升预测能力，但超过一定深度后收益递减。数据量方面，模型在数十亿词语料上训练可以捕获更丰富的语义和句法统计信息，但超过某一阈值后提升有限。研究还比较了微调模型在特定任务（如翻译、问答）上的表现，结果显示针对下游任务的微调有时会降低脑拟合度，可能因模型过拟合任务数据而破坏其通用表征。这提示我们，在构建大脑对齐的语言模型时，应平衡任务适应与通用语言知识的保持。此外，集成建模涵盖的神经数据主要来自英语，未来应引入其他语言和文化的脑数据，将模型的普适性检验扩展到更广泛的语言生态。
