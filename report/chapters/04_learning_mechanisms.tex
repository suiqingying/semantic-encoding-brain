\section{学习机制与模型：自监督语音与Transformer}

\subsection{自监督语音模型 wav2vec 2.0}
人工语音学习通常不依赖大规模标注，因此自监督语音模型能更贴近人类语言获得的条件。Millet 等（2023）\cite{Millet2023}考察了自监督语音模型 wav2vec 2.0\cite{Baevski2020} 与大脑活动的对应性。wav2vec 2.0 由三个主要部分组成：一个由七个卷积块构成的特征编码器，将原始 16 kHz 语音转换为低维潜在表示；一个量化模块，将连续表示映射为有限的离散符号词典；以及一个 12 层的 Transformer 上下文网络，通过自注意机制整合长距离信息。模型的自监督训练目标是预测被掩码帧的离散表示，训练引入对比损失和多样性损失，使模型既能依赖上下文，又能充分利用离散向量。

作者比较了随机初始化、自监督训练、监督训练以及跨语言训练的模型，并以这些模型的层级表示为特征，建立线性回归预测多个受试者聆听有声书时的 fMRI 响应。研究发现，自监督模型在大约 600 小时未标记语音上即可学习出与人脑相似的表示，模型的卷积层、量化层和 Transformer 层分别对应人类语音皮层的不同处理阶段。中层表示在听觉皮层和颞上沟表现最佳，后层 Transformer 表示则更符合语言皮层的反应。这些趋势在法语和普通话受试者中同样显现，表明自监督模型捕获了跨语言的声学与语音规律。行为实验结果也显示，模型的层级专化与人类语音辨别任务表现一致。

Millet 等的分析还指出，自监督模型的成功不仅依赖大规模训练数据，还受数据多样性和音频质量的影响。他们训练了不同尺寸的模型，发现 50 小时的数据即可学习基本的声学表示，但在更高语音层级（如音节、韵律）上需要数百小时的数据才能达到与大脑类似的层级专化。此外，作者比较了在单个语言和混合语言数据上训练的模型，发现跨语言训练的模型能更好地泛化到新语言并保持与大脑的高匹配度。这意味着，模型在学习语音规律时可能捕获了普遍的声学约束而非特定语言的词汇规则。他们还探索了监督学习模型（如声学—词法一体化模型），发现这类模型在高层表示上过度偏向目标任务（如字符识别），与大脑的匹配度反而下降。因此，自监督学习在模拟人类语言习得方面具有优势，未来可将其推广到更复杂的音系与语调结构，并与基于预测的语言模型整合。

自监督语音模型的优势不仅在于不依赖人工标签，还在于能够捕获语言通用的韵律和声学特征。wav2vec 2.0 的特征编码器由七个卷积模块组成，每个模块通过步长和卷积核大小控制时间分辨率和特征维度。在训练过程中，模型通过对比学习鼓励不同语音片段具有辨别性，同时利用量化模块构建离散的代码本，使连续语音表示能够映射到有限的符号集合。这些符号类似于音素或音节的抽象单位，为后续上下文网络提供清晰的离散输入。研究表明，自监督模型的不同层在处理语音的各个阶段表现出特定功能：早层卷积层对短时间帧的频谱特征敏感，中层表示音节和共振峰结构，后层 Transformer 捕获语调、词汇和发音风格。相比之下，监督训练的声学模型往往过度优化于特定标注任务，如语音识别或声学模型，从而导致其内部表示失去通用性，无法很好地解释大脑数据。通过在多种语言和方言上训练自监督模型，可以构建语言无关的声学基底，然后在此基础上微调特定语言的声学和语音特征。这一策略有望缩小模型与大脑在语音处理上的差距，特别是在处理口音、方言和情绪时。

\subsection{Transformer 的计算与功能专化}
Transformer 通过多层的自注意机制处理序列信息。此前研究多关注模型的隐向量嵌入，而 Kumar 等（2024）\cite{Kumar2024}直接分析了注意头执行的变换，即每个注意头如何更新词表示。他们将模型的变换分解为每个头的线性变换，并使用自然听故事的 fMRI 数据评估其预测能力。结果显示，注意头变换在语言皮层大部分区域能解释大量方差，且在后颞区显著优于传统语言学特征（如词性或句法依存关系）。不同层的头展示出渐进式的功能梯度：早层、短距离回溯的头权重在后侧颞区更高，而高层、长距离回溯的头则在前颞与前额叶区域占优势。这种梯度与语言处理从局部到全局的层次结构一致。

此外，作者发现某些特定头对特定语法依存关系（如补语从句、直接宾语）有选择性，在后颞区表现尤为明显。值得注意的是，在角回等高级语义区域，非上下文嵌入的预测能力反而超过了变换，这表明这些区域可能整合全局语义内容而非依赖局部注意。作者强调，头部变换只是模型的线性近似，不代表大脑的真实计算，但这种方法提供了更加细粒度的功能对齐视角。他们建议未来探索瓶颈 Transformer 等新架构，引入声学特征，并结合行为和语言任务，通过梯度约束和多任务学习进一步靠近大脑机制。

Transformer 的自注意框架不仅提供了线性近似，还可能在不同层捕获句法层次、共指链和话语主题等丰富信息。近期分析发现，注意头不仅沿层次形成回溯距离的梯度，还沿功能类别发生分化。例如部分头专注于主谓一致、名词短语结构，另一些头捕获语气助词和焦点标记，反映语用提示。更重要的是，头与头之间存在协调机制：在处理长句或嵌套从句时，前层的局部头预先筛选相关修饰语，后层的全局头再根据语篇结构整合信息。实验表明，当人为阻塞关键注意头时，模型在脑编码任务上的预测性能会显著下降，这支持了头之间协同工作的观点。进一步的诊断显示，注意分布与人类阅读的眼动轨迹相关，高层注意与长距离回溯的阅读阶段吻合，说明模型学习到了与人类相似的注意模式。

未来研究可以在模型中纳入生物约束，如稀疏连接和时间常数，使注意机制更贴近突触动力学。例如可以采用动态稀疏化策略限制每层仅激活少数关键头，并让头的权重随时间衰减，模拟大脑对旧信息的遗忘。此外，可以结合符号化模块，将注意头分配给特定的句法功能或语义角色，实现可解释性更强的混合模型。鉴于不同头在不同语言和任务上的作用存在差异，跨语言分析注意模式将有助于识别普遍与特定的注意策略。通过这些改进，我们期望 Transformer 不仅在行为表现上接近人类，还能在内部计算上更符合大脑的层次组织。

此外，注意头的输出可视为一系列线性变换，将当前词向量映射到多个上下文子空间。研究显示，这些变换在处理隐喻、修辞重复和语调变化时表现出特定的模式，表明模型内部对语义和语用的编码比单纯词级向量更丰富。一些工作提出将注意机制与可微栈或记忆模块结合，捕捉跨句段乃至跨文档的长期依存。将这些结构嵌入语言模型，或可更好模拟大脑在保持情节线索和角色身份时的持久性。由于自注意计算的复杂度随序列长度平方增长，与大脑的时间和能量约束不符，近年出现的稀疏或线性注意机制能够在提高效率的同时保留建模能力。这些机制也许更贴近大脑的局部连接和长距离白质束传导特性。对 Transformer 计算的深入理解和重构，将推动下一代高效且生理友好的模型，为解释大脑语言加工提供更多线索。

除了自监督和预测式学习机制外，最近的研究还探索了对比学习、变换器自回归与去噪自编码器结合的框架，以更全面地模拟语言习得。例如，带噪预训练的文本编码器通过随机遮挡句子片段并要求模型复原原句，在学习恢复局部信息的同时，还培养了对全局语义和句法的理解。这种任务结合了预测和重建两个目标，既包含自底向上的模式提取，也包含自顶向下的生成假设。实验证明，这类模型在脑编码任务中表现优异，尤其在预测内侧前额叶和角回等高层语义区域的活动时超越传统自回归模型。另一些研究引入了元学习和持续学习框架，使模型能够在不断变化的语料环境中适应新的语言模式，同时保留旧知识。这与大脑在终生学习中不断更新语义地图的过程类似。将这些先进的学习策略与神经数据对比，不仅可以评估它们的生物合理性，还可以揭示大脑可能采用的学习策略组合。
