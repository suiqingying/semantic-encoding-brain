\begin{AbstractBox}
近年来，深度学习技术与认知神经科学的交叉研究为理解人类语言处理机制开辟了新途径。本文综述了神经语言模型与大脑语义表征对比研究的最新进展，涵盖预测编码理论及其争议、语义系统的脑映射、自监督学习机制、Transformer架构的功能专化、组合语义表征以及跨语言和跨模态比较等核心主题。研究表明，语言模型在脑编码任务中的成功可能源于其捕获的丰富语言统计结构，而非单纯的预测机制。语义系统呈现分布式和网络化特征，涉及默认模式网络、注意网络等多个功能网络的协同作用。本综述旨在整合现有研究成果，揭示人工神经网络与大脑语言处理的对应关系，并指出未来研究的关键方向。
\end{AbstractBox}
